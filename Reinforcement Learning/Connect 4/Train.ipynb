{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74676f8-8fb9-4222-b79b-6836f5ec26ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f99eac-cae4-4d4e-b10d-75f37865d78e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25683ec0-5a13-4171-b534-9a7a3509b522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this class plays the games\n",
    "class conny4:\n",
    "    \n",
    "    def __init__(self, start_board = np.zeros((6,7))):\n",
    "        self.board = copy.deepcopy(start_board)\n",
    "        self.player = self.player()\n",
    "\n",
    "        if np.sum(self.board) == 1:\n",
    "            self.player.player = 'Y'\n",
    "        elif np.sum(self.board) == 0:\n",
    "            self.player.player = 'R'\n",
    "        else:\n",
    "            self.board = np.zeros((6,7))\n",
    "    \n",
    "    class player:\n",
    "        def __init__(self):\n",
    "            self.player = None\n",
    "            self.player_swap = {'R':'Y', 'Y':'R'}\n",
    "            self.player_score = {'R':1, 'Y':-1}\n",
    "            self.player_name = {'R':'Red', 'Y':'Yellow'}\n",
    "    \n",
    "    def legal(self):\n",
    "        leg = []\n",
    "        if not self.game_end()[0]:\n",
    "            for i in range(7):\n",
    "                if self.board[0,i] == 0:\n",
    "                    leg.append(i)\n",
    "        return(leg)\n",
    "        \n",
    "    def turn(self, pos):\n",
    "        if pos not in self.legal():\n",
    "            pass\n",
    "        else:\n",
    "            self.board[sum(np.where(self.board[:,pos] == 0, 1 ,0)) - 1,pos] = self.player.player_score[self.player.player]\n",
    "            if not self.game_end()[0]:\n",
    "                self.player.player = self.player.player_swap[self.player.player]\n",
    "    \n",
    "    def game_end(self):\n",
    "        if self.score_update() == 4:\n",
    "            return(True,self.player.player_score[self.player.player])\n",
    "        elif sum(sum(np.where(self.board == 0, 1,0))) == 0:\n",
    "            return(True,0)\n",
    "        else:\n",
    "            return(False,)\n",
    "    \n",
    "    def score_update(self):\n",
    "        for i in range(3):\n",
    "            for j in range(4):\n",
    "                x4 = self.board[i:4+i,j:4+j]\n",
    "                hors = [abs(sum(x4[:,k])) for k in range(4)]\n",
    "                vers = [abs(sum(x4[k,:])) for k in range(4)]\n",
    "                diag = [abs(np.trace(x4)),abs(np.trace(np.flip(x4,0)))]\n",
    "                score = max(hors+vers+diag)\n",
    "                if score == 4:\n",
    "                    return(score)\n",
    "        return(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52258ba1-576b-42c3-aff6-131b1939aac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#empty class for initial games when nothing is known\n",
    "class default_model:\n",
    "    def __init__(self, st_va):\n",
    "        self.st_va = st_va\n",
    "    def predict(self, state):\n",
    "        if state in self.st_va:\n",
    "            return (self.st_va[state.tobytes()])\n",
    "        else:\n",
    "            return(0)\n",
    "\n",
    "# this function iterates playing the conny4 class against itself using a model, then outputs the dictionary of states visisted, and the values determined through value iteration.\n",
    "def q_l(model = default_model(st_va = {}), games = 100, learn_rate = 0.1, discount = 0.9, exploit = 0.5, seed = 0):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    count = 0\n",
    "    st_va = {}\n",
    "    for i in range(games):\n",
    "        \n",
    "        game = conny4()\n",
    "        states = [np.copy(game.board)]\n",
    "        count += 1\n",
    "        # play until end game\n",
    "        while not game.game_end()[0]:\n",
    "            if np.random.rand() > exploit:\n",
    "                state = game.board\n",
    "                legal = game.legal()\n",
    "                np.random.shuffle(legal)\n",
    "                scores = {}\n",
    "                \n",
    "                for i in legal:\n",
    "                    game.turn(i)\n",
    "                    if game.game_end()[0]:\n",
    "                        scores[i] = game.game_end()[1]\n",
    "                    else:\n",
    "                        scores[i] = -1*model.predict(game.board)*game.player.player_score[game.player.player]\n",
    "                    game = conny4(start_board = state)\n",
    "                    \n",
    "                move = max(scores, key = scores.get)\n",
    "            else:\n",
    "                legal = game.legal()\n",
    "                np.random.shuffle(legal)\n",
    "                move = legal[0]\n",
    "                \n",
    "            game.turn(move)\n",
    "            states.append(np.copy(game.board))\n",
    "        \n",
    "        # game ends, perform value iteration\n",
    "        reward = game.game_end()[1]\n",
    "        st_va[states[-1].tobytes()] = reward\n",
    "        for i in reversed(states[:-1]):\n",
    "            if i.tobytes() not in st_va:\n",
    "                st_va[i.tobytes()] = 0\n",
    "                st_va[np.fliplr(i).tobytes()] = 0\n",
    "            st_va[i.tobytes()] = ((1 - learn_rate)*st_va[i.tobytes()]) + (learn_rate*(discount*reward))\n",
    "            st_va[np.fliplr(i).tobytes()] = ((1 - learn_rate) * st_va[np.fliplr(i).tobytes()]) + (learn_rate*(discount*reward))\n",
    "            reward = reward * discount\n",
    "    \n",
    "    return(st_va)\n",
    "\n",
    "def merge_dicts(dict_arr, st_va = None):\n",
    "    c = Counter(st_va)\n",
    "    for dic in dict_arr:\n",
    "        c.update(Counter(dic))\n",
    "    sums = dict(c)\n",
    "    means = {k: sums[k] / sum((1 for dic in dict_arr if k in dic)) for k in sums}\n",
    "    return means\n",
    "\n",
    "def time_taken(x=3665):\n",
    "    print(f'Time Taken: {np.floor((x)/(60*60))}H: {np.floor( ((x)%(60*60))/60 )}M: {np.floor( ((x)%(60)) )}S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ae48a-49c2-4cf4-ab90-9a01b76c4829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cores = 5\n",
    "\n",
    "args = []\n",
    "for i in range(cores):\n",
    "    args.append((default_model({}), 1000000, 0.1, 0.9, 1, np.random.randint(2147483647)))\n",
    "with Pool(processes = cores) as p:\n",
    "    st_va = merge_dicts(p.starmap(q_l, args))\n",
    "\n",
    "time_taken(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5759698-d469-4331-954a-7c4b8b46bc5d",
   "metadata": {},
   "source": [
    "# 2.7M states (from 1M games) uses roughly 12gb memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51630ac-d88d-41b3-91e7-54930757efad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.array([np.reshape(np.frombuffer(i), newshape=(6, 7, 1)) for i in st_va])\n",
    "y = np.array([st_va[i] for i in st_va])\n",
    "del(st_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b02fd-b5ee-4622-ba66-fc9aa3c082d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e46762-5ef9-4378-8a3e-a83bc05b4079",
   "metadata": {},
   "source": [
    "# Construct and tune CNN on base data which will be updated with incremental training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c61a39-696e-4aeb-8d38-80c43d52e902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Conv2D, Concatenate, Dropout, Flatten\n",
    "from tensorflow.keras import Model, Input\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6eb664-ebbc-4f3f-810f-527fd8ec1f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f29377-5aef-4c22-bb45-bab442beed31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = Input(shape=(6, 7, 1))\n",
    "tower_1 = Conv2D(32, (4, 4), padding='same', activation='relu')(input_shape)\n",
    "tower_2 = Conv2D(32, (2, 2), padding='same', activation='relu')(input_shape)\n",
    "tower_3 = Conv2D(32, (1, 1), padding='same', activation='relu')(input_shape)\n",
    "merged = Concatenate()([tower_1, tower_2, tower_3])\n",
    "out = Flatten()(merged)\n",
    "conv_model = Model(input_shape, out)\n",
    "\n",
    "def model_builder(hp):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(conv_model)\n",
    "    \n",
    "    hp_units = hp.Int('units_1', min_value=8, max_value=512, step=32)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "      \n",
    "    hp_fl = hp.Float('drop_1', 0.1, 0.5)\n",
    "    model.add(Dropout(hp_fl))\n",
    "    \n",
    "    hp_units = hp.Int('units_2', min_value=8, max_value=512, step=32)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    hp_fl = hp.Float('drop_2', 0.1, 0.5)\n",
    "    model.add(Dropout(hp_fl))\n",
    "    \n",
    "    hp_units = hp.Int('units_3', min_value=8, max_value=256, step=16)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    hp_fl = hp.Float('drop_3', 0.1, 0.5)\n",
    "    model.add(Dropout(hp_fl))\n",
    "    \n",
    "    hp_units = hp.Int('units_4', min_value=8, max_value=128, step=8)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    hp_units = hp.Int('units_5', min_value=8, max_value=64, step=4)\n",
    "    model.add(Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-1, sampling=\"log\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                  metrics=[tf.keras.metrics.MeanAbsoluteError(),\n",
    "                           tf.keras.metrics.LogCoshError()])\n",
    "    return model\n",
    "\n",
    "model_builder(kt.HyperParameters()) #tests that model compiles correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af9c70-60e8-403a-bc9d-41895083ee3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = \"mean_absolute_error\",\n",
    "                     max_epochs = 200,\n",
    "                     overwrite = True,# need to have a directory so will overwrite it everytime ez\n",
    "                     project_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d34cd-5ba1-4d4e-a41e-94e8376a18e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "import warnings \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #removes depreaction warnings (of which there are loads)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='mean_absolute_error', patience=5)\n",
    "tuner.search(X, y, \n",
    "             epochs = 50,\n",
    "             validation_split = 0.2,\n",
    "             callbacks = [callback],\n",
    "             verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa5126-8c00-479b-892e-b3b163edf544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_taken(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232d825-782a-4ce5-b7a7-f4517887e0d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tuner.get_best_hyperparameters()[0]\n",
    "model = tuner.hypermodel.build(model)\n",
    "model.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50cc338-989d-4d4b-9bc5-7029c0abd40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/home/conny4-Model'\n",
    "model.save(path)\n",
    "#tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb581585-a024-4c18-979b-b8bc8de6ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finito') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe57fc-c142-47e6-b4ae-43c190a93f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters(num_trials = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7fd41-9a0a-4943-ab17-01637c881d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d56fc7f-30c4-42f8-b176-4bdd16e62c0b",
   "metadata": {},
   "source": [
    "### Plan going forwards\n",
    "\n",
    "With this we have ran 1mil games in parallel and used them to determine best parameters for CNN.\n",
    "Using this as our CNN, we will do the following to fully train the model:\n",
    "\n",
    "1. Run 1 mil games with current CNN.\n",
    "2. Plug score dictionary into CNN - incremental learning with train_on_batch <br> https://stackoverflow.com/questions/64796163/is-incremental-learning-possible-with-tensorflow.\n",
    "4. Adjust exploit rate in `Q_L` class and learning_rate in the CNN.\n",
    "5. Repeat steps 1-4.\n",
    "\n",
    "To adjust the exploit rate and learning rates well i have developed the below function to map interative calls to a desired function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafe153-bb73-4486-b405-29d594a2bb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
