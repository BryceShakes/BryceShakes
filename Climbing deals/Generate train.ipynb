{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0106219-6406-4fec-8d25-d48d116d3e0b",
   "metadata": {},
   "source": [
    "# Labelled Dataset\n",
    "The filtering requires a model, based on my preferences. This developes the labelled data as described below\n",
    "\n",
    "I dont want to reccomend clothes (im not a sweat) so i will get rid of all that shite, and some other items id not be intersted in. \n",
    "Filter based on image or text either agg or stack after convolution idk\n",
    "\n",
    "    step 1- Generate target, will do this manually :( - binary if interested or not\n",
    "    step 2- tokenise label into usable format\n",
    "    step 3- go from images link to actual image (should all be 150 by 150 to make things easier)\n",
    "    step 4- build models ??\n",
    "        idea 1 - two models, agg results\n",
    "        idea 2 - one model, stack text data after convolution??\n",
    "        idea 3 - towered approach\n",
    "            do convolution -> some dense layers\n",
    "            do text -> some dense layers.\n",
    "            stack outputs arrs from there on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ad8a0-df7b-4f5d-a999-d77f5d5cb807",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "lets get some targets. To make it easier ill randomly order the items, present them one at a time (just title and photo) then label whatever is presented. update into an array, stop whenever i get bored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf2da7d-8001-4e7b-9a09-068d6c854bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climbing_scraper import scraper\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d3fe15-2405-4bb1-8681-1a9fb2a9d58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bryce/BryceShakes/Climbing deals'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3c953-cbda-41a5-8cc3-1b607d4530c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scraper.scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279c324-6533-44e5-a2e3-27bbbc04f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "df = df.sample(frac = 1)[['item_name','img_link']] # shuffle them all\n",
    "for i in range(len(df)): \n",
    "    display(HTML(df.iloc[[i]].to_html(escape=False, formatters=format_dict, index = False))) #display row\n",
    "    inp = input() # request input\n",
    "    if inp not in ['1', '0']: # can exit if bored\n",
    "        clear_output(wait = True)\n",
    "        print(f'Not 0 or 1, ending labelling at {len(arr)} items')\n",
    "        break\n",
    "    arr.append(inp) # append 0 or 1\n",
    "    clear_output(wait = True) # clear output for next item\n",
    "\n",
    "df = df.iloc[:len(arr)].reset_index( drop = True)\n",
    "df['label'] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e746f-bf85-4f1f-a4b1-518ab8bc8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path = f'{os.getcwd()}/labeled_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
